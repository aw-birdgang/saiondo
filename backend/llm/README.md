# Saiondo LLM Server

FastAPI(Python) ê¸°ë°˜ì˜ LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸) ì—°ë™ ì„œë²„ì…ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡°**

llm/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.py # FastAPI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”‚ â”œâ”€â”€ routes.py # API ë¼ìš°í„°
â”‚ â”œâ”€â”€ llm.py # LLM ì„œë¹„ìŠ¤ ì¶”ìƒí™”
â”‚ â”œâ”€â”€ schemas.py # Pydantic ë°ì´í„° ëª¨ë¸
â”‚ â”œâ”€â”€ providers/ # LLM API ì—°ë™(OpenAI, Claude ë“±)
â”‚ â”œâ”€â”€ mcp/ # ëŒ€í™” context ë“± ë„ë©”ì¸ ë¡œì§
â”‚ â””â”€â”€ graph/ # ê·¸ë˜í”„/ë¶„ì„ ê´€ë ¨ ë¡œì§
â”œâ”€â”€ requirements.txt # Python ì˜ì¡´ì„±
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â””â”€â”€ venv/ # (ë¡œì»¬ ê°€ìƒí™˜ê²½, git ë¯¸í¬í•¨)

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë° ê°œë°œ íŒ¨í„´

- **FastAPI ê¸°ë°˜ REST API ì„œë²„**
- **ì„œë¹„ìŠ¤ ê³„ì¸µ ë¶„ë¦¬**:  
  - `routes.py`ì—ì„œ ì—”ë“œí¬ì¸íŠ¸ ì •ì˜ â†’ `llm.py`/`providers/`ì—ì„œ ì‹¤ì œ LLM í˜¸ì¶œ
- **LLM Provider ì¶”ìƒí™”**:  
  - `src/providers/`ì— OpenAI, Claude ë“± ë‹¤ì–‘í•œ LLM ì—°ë™ êµ¬í˜„
- **Pydantic ê¸°ë°˜ ë°ì´í„° ê²€ì¦/ì§ë ¬í™”**
- **í™•ì¥ì„± ê³ ë ¤**:  
  - ìƒˆë¡œìš´ LLM, ë¶„ì„ ê·¸ë˜í”„, context ê´€ë¦¬ ë“± ì†ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥

## ğŸ§© ì£¼ìš” ë„ë©”ì¸

- **/chat**: í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ LLM ì‘ë‹µ API (OpenAI, Claude ë“± ì„ íƒ)
- **/analyze**: ì‚¬ìš©ì/íŒŒíŠ¸ë„ˆ í”„ë¡¬í”„íŠ¸, ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê´€ê³„ ë¶„ì„
- **/health**: í—¬ìŠ¤ì²´í¬
- **providers/**: LLM API ì—°ë™(OpenAI, Claude ë“±)
- **graph/**: ê´€ê³„ ë¶„ì„ ê·¸ë˜í”„, ë…¸ë“œ ë“±
- **mcp/**: ëŒ€í™” context ë“± ë„ë©”ì¸ë³„ ìœ í‹¸ë¦¬í‹°

## âš™ï¸ ê¸°ìˆ  ìŠ¤íƒ ë° ì£¼ìš” ì˜ì¡´ì„±

- **Python 3.11+**
- **FastAPI**: ì›¹ í”„ë ˆì„ì›Œí¬
- **Uvicorn**: ASGI ì„œë²„
- **Pydantic**: ë°ì´í„° ëª¨ë¸/ê²€ì¦
- **langchain, langgraph**: LLM ì›Œí¬í”Œë¡œìš°/ê·¸ë˜í”„
- **openai, requests**: ì™¸ë¶€ LLM API ì—°ë™
- **python-dotenv**: í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬

> ì£¼ìš” ì˜ì¡´ì„±ì€ `requirements.txt` ì°¸ê³ 

## ğŸš€ ê°œë°œ/ì‹¤í–‰/ë°°í¬

1. **ê°€ìƒí™˜ê²½ ìƒì„± ë° ì˜ì¡´ì„± ì„¤ì¹˜**
   ```sh
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```
2. **ê°œë°œ ì„œë²„ ì‹¤í–‰**
   ```sh
   uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
   ```
3. **Docker ë¹Œë“œ/ì‹¤í–‰**
   ```sh
   docker build -t saiondo-llm .
   docker run -p 8000:8000 saiondo-llm
   ```

### Dockerë¡œ ì‹¤í–‰

- **docker-compose ì—°ë™ ì˜ˆì‹œ**
  ```sh
  docker compose up -d llm
  ```

## ğŸ§ª í…ŒìŠ¤íŠ¸

- (ë³„ë„ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬/ì½”ë“œ ë¯¸í¬í•¨, FastAPI ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ ê¶Œì¥)
- ì˜ˆì‹œ:
  ```sh
  curl http://localhost:8000/health
  curl -X POST http://localhost:8000/chat -H "Content-Type: application/json" -d '{"prompt": "ì•ˆë…•!", "model": "openai"}'
  ```

## ğŸ› ï¸ ì£¼ìš” ëª…ë ¹ì–´

- **ê°€ìƒí™˜ê²½ ìƒì„±**
  ```sh
  python3 -m venv venv
  source venv/bin/activate
  ```
- **ì˜ì¡´ì„± ì„¤ì¹˜**
  ```sh
  pip install -r requirements.txt
  ```
- **ê°œë°œ ì„œë²„ ì‹¤í–‰**
  ```sh
  uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
  ```
- **Docker ë¹Œë“œ/ì‹¤í–‰**
  ```sh
  docker build -t saiondo-llm .
  docker run -p 8000:8000 saiondo-llm
  ```

## ğŸ›¡ï¸ Trouble Shooting

- **í™˜ê²½ë³€ìˆ˜ ëˆ„ë½**: OPENAI_API_KEY ë“±ì€ .env ë˜ëŠ” docker-composeë¡œ ì£¼ì… í•„ìš”
- **í¬íŠ¸ ì¶©ëŒ**: 8000 í¬íŠ¸ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸
- **ì™¸ë¶€ LLM API Key ì˜¤ë¥˜**: ì˜¬ë°”ë¥¸ í‚¤/ê¶Œí•œ í™•ì¸
- **íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì˜¤ë¥˜**: python, pip, venv ë²„ì „ í™•ì¸

## ğŸ—ï¸ ê¸°ì—¬/í™•ì¥

- ìƒˆë¡œìš´ LLM Provider ì¶”ê°€: `src/providers/`ì— êµ¬í˜„ í›„, `llm.py`ì— ë“±ë¡
- ìƒˆë¡œìš´ ë¶„ì„/ê·¸ë˜í”„ ê¸°ëŠ¥ ì¶”ê°€: `src/graph/`, `src/mcp/`ì— ëª¨ë“ˆ ì¶”ê°€
- FastAPI ë¼ìš°í„° í™•ì¥: `src/routes.py`ì— ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

## ğŸ“š ê¸°íƒ€

- API ì„œë²„(`api/`)ì—ì„œ HTTPë¡œ í˜¸ì¶œí•˜ì—¬ í†µí•© ì‚¬ìš©
- í™˜ê²½ë³€ìˆ˜, API Key ë“±ì€ .env ë˜ëŠ” docker-composeë¡œ ê´€ë¦¬
- ì˜ˆì‹œ curl ëª…ë ¹ì–´ ë° ìƒ˜í”Œ ìš”ì²­/ì‘ë‹µì€ README ìƒë‹¨ ì°¸ê³ 
