# SAIONDO LLM Server

**FastAPI(Python) ê¸°ë°˜ì˜ LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸) ì—°ë™ ì„œë²„**  
SAIONDOì˜ LLM ì„œë²„ëŠ” OpenAI, Claude ë“± ë‹¤ì–‘í•œ LLM Providerì™€ ì—°ë™í•˜ì—¬  
ì»¤í”Œ ëŒ€í™” ë¶„ì„, AI ì±—ë´‡, ì„±í–¥ ë¶„ì„, í”¼ë“œë°± ìˆ˜ì§‘ ë“± í•µì‹¬ AI ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡°

```
llm/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.py # FastAPI ì•± ì§„ì…ì 
â”‚ â”œâ”€â”€ config.py # í™˜ê²½ì„¤ì •/DI
â”‚ â”œâ”€â”€ api/ # ì—”ë“œí¬ì¸íŠ¸(ë¼ìš°í„°) ëª¨ë“ˆ
â”‚ â”‚ â”œâ”€â”€ chat.py # ê¸°ë³¸ ì±„íŒ… API
â”‚ â”‚ â”œâ”€â”€ chat_relationship_coach.py # ê´€ê³„ ì½”ì¹˜ ì±„íŒ…
â”‚ â”‚ â”œâ”€â”€ couple_analysis.py # ê¸°ë³¸ ì»¤í”Œ ë¶„ì„
â”‚ â”‚ â”œâ”€â”€ enhanced_couple_analysis.py # í–¥ìƒëœ ì»¤í”Œ ë¶„ì„
â”‚ â”‚ â”œâ”€â”€ batch_analysis.py # ë°°ì¹˜ ë¶„ì„
â”‚ â”‚ â”œâ”€â”€ feedback.py # í”¼ë“œë°± ìˆ˜ì§‘
â”‚ â”‚ â”œâ”€â”€ health.py # í—¬ìŠ¤ì²´í¬
â”‚ â”‚ â”œâ”€â”€ labeling.py # ë¼ë²¨ë§
â”‚ â”‚ â”œâ”€â”€ labeling_trait_vector.py # íŠ¹ì„± ë²¡í„° ë¼ë²¨ë§
â”‚ â”‚ â””â”€â”€ prompt.py # í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
â”‚ â”œâ”€â”€ services/ # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§(ì„œë¹„ìŠ¤) ëª¨ë“ˆ
â”‚ â”‚ â”œâ”€â”€ llm_provider.py # LLM ì¶”ìƒí™”/Provider
â”‚ â”‚ â”œâ”€â”€ chat_service.py # ì±„íŒ… ì„œë¹„ìŠ¤
â”‚ â”‚ â”œâ”€â”€ chat_relationship_coach_service.py # ê´€ê³„ ì½”ì¹˜ ì„œë¹„ìŠ¤
â”‚ â”‚ â”œâ”€â”€ couple_analysis_service.py # ê¸°ë³¸ ì»¤í”Œ ë¶„ì„
â”‚ â”‚ â”œâ”€â”€ enhanced_couple_analysis_service.py # í–¥ìƒëœ ì»¤í”Œ ë¶„ì„
â”‚ â”‚ â”œâ”€â”€ analysis_validator.py # ë°ì´í„° ê²€ì¦
â”‚ â”‚ â”œâ”€â”€ analysis_cache.py # ìºì‹± ì„œë¹„ìŠ¤
â”‚ â”‚ â”œâ”€â”€ feedback_service.py # í”¼ë“œë°± ì„œë¹„ìŠ¤
â”‚ â”‚ â”œâ”€â”€ labeling_service.py # ë¼ë²¨ë§ ì„œë¹„ìŠ¤
â”‚ â”‚ â”œâ”€â”€ labeling_trait_vector_service.py # íŠ¹ì„± ë²¡í„° ì„œë¹„ìŠ¤
â”‚ â”‚ â””â”€â”€ prompt_service.py # í”„ë¡¬í”„íŠ¸ ì„œë¹„ìŠ¤
â”‚ â”œâ”€â”€ schemas/ # Pydantic ë°ì´í„° ëª¨ë¸
â”‚ â”‚ â”œâ”€â”€ chat.py
â”‚ â”‚ â”œâ”€â”€ chat_relationship_coach.py
â”‚ â”‚ â”œâ”€â”€ couple_analysis.py
â”‚ â”‚ â”œâ”€â”€ enhanced_couple_analysis.py
â”‚ â”‚ â”œâ”€â”€ feedback.py
â”‚ â”‚ â”œâ”€â”€ labeling.py
â”‚ â”‚ â”œâ”€â”€ labeling_trait_vector.py
â”‚ â”‚ â””â”€â”€ prompt.py
â”‚ â”œâ”€â”€ providers/ # LLM Provider êµ¬í˜„
â”‚ â”‚ â”œâ”€â”€ openai_client.py # OpenAI API í´ë¼ì´ì–¸íŠ¸
â”‚ â”‚ â””â”€â”€ claude_client.py # Claude API í´ë¼ì´ì–¸íŠ¸
â”‚ â”œâ”€â”€ core/ # í•µì‹¬ ìœ í‹¸ë¦¬í‹°
â”‚ â”‚ â””â”€â”€ labeling/ # ë¼ë²¨ë§ ê´€ë ¨ ìœ í‹¸ë¦¬í‹°
â”‚ â”œâ”€â”€ graph/ # LangGraph ì›Œí¬í”Œë¡œìš°
â”‚ â”‚ â”œâ”€â”€ nodes.py # ê·¸ë˜í”„ ë…¸ë“œ ì •ì˜
â”‚ â”‚ â””â”€â”€ love_analysis_graph.py # ì‚¬ë‘ ë¶„ì„ ê·¸ë˜í”„
â”‚ â”œâ”€â”€ mcp/ # Model Context Protocol
â”‚ â”‚ â””â”€â”€ context.py # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
â”‚ â””â”€â”€ tests/ # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”‚ â”œâ”€â”€ test_enhanced_couple_analysis.py
â”‚ â””â”€â”€ labeling/
â”œâ”€â”€ docs/ # ë¬¸ì„œ
â”‚ â””â”€â”€ langsmith-guide.md # LangSmith ê°€ì´ë“œ
â”œâ”€â”€ puml/ # PlantUML ë‹¤ì´ì–´ê·¸ë¨
â”œâ”€â”€ requirements.txt # Python ì˜ì¡´ì„±
â”œâ”€â”€ Dockerfile # Docker ì´ë¯¸ì§€
â”œâ”€â”€ Dockerfile.dev # ê°œë°œìš© Docker ì´ë¯¸ì§€
â”œâ”€â”€ run_server.sh # ì„œë²„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ .env.example # í™˜ê²½ë³€ìˆ˜ ì˜ˆì‹œ
â””â”€â”€ README.md # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë° ê°œë°œ íŒ¨í„´

### **ê³„ì¸µ êµ¬ì¡°**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API Layer                 â”‚
â”‚  (FastAPI Routers)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Service Layer              â”‚
â”‚  (Business Logic)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        Provider Layer              â”‚
â”‚  (LLM Integration)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Core Layer                 â”‚
â”‚  (Utilities & Helpers)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§© ì£¼ìš” ë„ë©”ì¸

- **/chat**: í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ LLM ì‘ë‹µ API (OpenAI, Claude ë“± ì„ íƒ)
- **/analyze**: ì‚¬ìš©ì/íŒŒíŠ¸ë„ˆ í”„ë¡¬í”„íŠ¸, ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê´€ê³„ ë¶„ì„
- **/feedback**: ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘/ì €ì¥
- **/health**: í—¬ìŠ¤ì²´í¬
- **providers/**: LLM API ì—°ë™(OpenAI, Claude ë“±)
- **graph/**: ê´€ê³„ ë¶„ì„ ê·¸ë˜í”„, ë…¸ë“œ ë“±
- **mcp/**: ëŒ€í™” context ë“± ë„ë©”ì¸ë³„ ìœ í‹¸ë¦¬í‹°

## âš™ï¸ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒ

- **Python 3.11+**
- **FastAPI**: ì›¹ í”„ë ˆì„ì›Œí¬
- **Uvicorn**: ASGI ì„œë²„
- **Pydantic**: ë°ì´í„° ëª¨ë¸/ê²€ì¦
- **langchain, langgraph**: LLM ì›Œí¬í”Œë¡œìš°/ê·¸ë˜í”„
- **openai, requests**: ì™¸ë¶€ LLM API ì—°ë™
- **python-dotenv**: í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬
- **langsmith**: LLM íŠ¸ë ˆì´ì‹±/ì‹¤í—˜/í‰ê°€ (ì˜µì…˜)

> ì£¼ìš” ì˜ì¡´ì„±ì€ `requirements.txt` ì°¸ê³ 

## ğŸš€ ì‹¤í–‰ ë°©ë²• (ë¡œì»¬ ê°œë°œ í™˜ê²½)

### 1. **ê°€ìƒí™˜ê²½ ìƒì„± ë° ì˜ì¡´ì„± ì„¤ì¹˜**

```sh
cd llm
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. **í™˜ê²½ë³€ìˆ˜(.env) ì„¤ì •**

- `.env.example` íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³ , í•„ìš”í•œ API Key ë° í™˜ê²½ë³€ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
  ```
  cp .env.example .env
  # .env íŒŒì¼ì„ ì—´ì–´ OPENAI_API_KEY ë“± ê°’ ì…ë ¥
  ```

### 3. **ê°œë°œ ì„œë²„ ì‹¤í–‰**

```sh
cd backend/llm
PYTHONPATH=src uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
```
- ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©´, [http://localhost:8000/docs](http://localhost:8000/docs)ì—ì„œ Swagger UIë¡œ APIë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ³ Dockerë¡œ ì‹¤í–‰

### 1. **Docker ì´ë¯¸ì§€ ë¹Œë“œ**

```sh
docker build -t saiondo-llm .
```

### 2. **ì»¨í…Œì´ë„ˆ ì‹¤í–‰**

```sh
docker run --env-file .env -p 8000:8000 saiondo-llm
```

## ğŸ”„ **ì£¼ìš” ê°œì„ ì‚¬í•­**

### **1. êµ¬ì¡° ì—…ë°ì´íŠ¸**
- í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ í´ë” êµ¬ì¡° ì™„ì „ ì—…ë°ì´íŠ¸
- ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë“ˆë“¤ ë°˜ì˜ (enhanced_couple_analysis, batch_analysis ë“±)

### **2. API ë¬¸ì„œí™” ê°•í™”**
- ì‹¤ì œ API ì—”ë“œí¬ì¸íŠ¸ì™€ ì‚¬ìš© ì˜ˆì‹œ ì¶”ê°€
- curl ëª…ë ¹ì–´ë¡œ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ì˜ˆì‹œ ì œê³µ

### **3. ê°œë°œ ê°€ì´ë“œ í™•ì¥**
- ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ë°©ë²• ìƒì„¸ ê°€ì´ë“œ
- LangGraph ì›Œí¬í”Œë¡œìš° ì¶”ê°€ ë°©ë²•
- LLM Provider í™•ì¥ ë°©ë²•

### **4. í…ŒìŠ¤íŠ¸ ì„¹ì…˜ ì¶”ê°€**
- pytest ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë°©ë²•
- í…ŒìŠ¤íŠ¸ êµ¬ì¡° ë° ì»¤ë²„ë¦¬ì§€ ì •ë³´

### **5. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…**
- LangSmith íŠ¸ë ˆì´ì‹± ì„¤ì •
- êµ¬ì¡°í™”ëœ ë¡œê¹… ì„¤ì •
- ë””ë²„ê¹… ë°©ë²•

### **6. ë°°í¬ ê°€ì´ë“œ**
- Production í™˜ê²½ ì„¤ì •
- Docker ë°°í¬ ë°©ë²•
- Gunicorn ì‚¬ìš©ë²•

### **7. ë¬¸ì œ í•´ê²° ì„¹ì…˜**
- ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²° ë°©ë²• í…Œì´ë¸”
- ë””ë²„ê¹… ëª…ë ¹ì–´

### **8. ê¸°ì—¬ ê°€ì´ë“œ**
- Pull Request í”„ë¡œì„¸ìŠ¤
- ì½”ë“œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
- ê°œë°œ í™˜ê²½ ì„¤ì •

ì´ì œ README.mdê°€ í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°ì™€ ì™„ì „íˆ ì¼ì¹˜í•˜ë©°, ê°œë°œìë“¤ì´ ì‰½ê²Œ í”„ë¡œì íŠ¸ë¥¼ ì´í•´í•˜ê³  ê¸°ì—¬í•  ìˆ˜ ìˆë„ë¡ ìµœì í™”ë˜ì—ˆìŠµë‹ˆë‹¤!

## ğŸ”§ ê°œë°œ ê°€ì´ë“œ

### **ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€**

1. **ìŠ¤í‚¤ë§ˆ ì •ì˜** (`src/schemas/`)
```python
from pydantic import BaseModel

class NewRequest(BaseModel):
    field: str

class NewResponse(BaseModel):
    result: str
```

2. **ì„œë¹„ìŠ¤ ë¡œì§** (`src/services/`)
```python
class NewService:
    def process(self, data: str) -> str:
        return f"Processed: {data}"

new_service = NewService()
```

3. **API ì—”ë“œí¬ì¸íŠ¸** (`src/api/`)
```python
from fastapi import APIRouter
from schemas.new import NewRequest, NewResponse
from services.new_service import new_service

router = APIRouter()

@router.post("/new", response_model=NewResponse)
def new_endpoint(request: NewRequest):
    result = new_service.process(request.field)
    return NewResponse(result=result)
```

4. **ë©”ì¸ ì•±ì— ë“±ë¡** (`src/main.py`)
```python
from api.new import router as new_router
app.include_router(new_router)
```

### **ìƒˆë¡œìš´ LLM Provider ì¶”ê°€**

1. **Provider í´ë¼ì´ì–¸íŠ¸** (`src/providers/`)
```python
def ask_new_llm(prompt: str) -> str:
    # ìƒˆë¡œìš´ LLM API í˜¸ì¶œ ë¡œì§
    return response
```

2. **LLM Providerì— ë“±ë¡** (`src/services/llm_provider.py`)
```python
from providers.new_client import ask_new_llm

class LLMProvider:
    def ask(self, prompt: str, model: str = None) -> str:
        if model == "new_llm":
            return ask_new_llm(prompt)
        # ... ê¸°ì¡´ ë¡œì§
```

### **LangGraph ì›Œí¬í”Œë¡œìš° ì¶”ê°€**

1. **ë…¸ë“œ ì •ì˜** (`src/graph/nodes.py`)
```python
def new_analysis_node(state):
    # ë¶„ì„ ë¡œì§
    return {"result": "analysis_result"}
```

2. **ê·¸ë˜í”„ êµ¬ì„±** (`src/graph/new_graph.py`)
```python
from langgraph.graph import StateGraph

def create_new_graph():
    workflow = StateGraph(StateType)
    workflow.add_node("analyze", new_analysis_node)
    return workflow.compile()
```

## ğŸ¤ ë¬¸ì œ í•´ê²°

### **ì¼ë°˜ì ì¸ ë¬¸ì œ**

| ë¬¸ì œ | í•´ê²° ë°©ë²• |
|------|-----------|
| í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ | `.env` íŒŒì¼ì— í•„ìˆ˜ API í‚¤ í™•ì¸ |
| í¬íŠ¸ ì¶©ëŒ | ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©: `--port 8001 |
| LLM API ì˜¤ë¥˜ | API í‚¤ ìœ íš¨ì„± ë° í• ë‹¹ëŸ‰ í™•ì¸ |
| íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì˜¤ë¥˜ | Python ë²„ì „ í™•ì¸ (3.11+) |
| Redis ì—°ê²° ì˜¤ë¥˜ | Redis ì„œë²„ ì‹¤í–‰ ë˜ëŠ” ìºì‹± ë¹„í™œì„±í™” |

### **ë””ë²„ê¹…**

```bash
# ìƒì„¸ ë¡œê·¸ì™€ í•¨ê»˜ ì‹¤í–‰
uvicorn src.main:app --reload --log-level debug

# íŠ¹ì • ëª¨ë“ˆ ë¡œê·¸ í™•ì¸
export PYTHONPATH=src
python -c "from services.llm_provider import llm_provider; print(llm_provider.ask('test'))"
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### **LangSmith íŠ¸ë ˆì´ì‹±**

```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export LANGCHAIN_TRACING_V2=true
export LANGCHAIN_API_KEY=your-key
export LANGCHAIN_PROJECT=saiondo-llm

# ì„œë²„ ì‹¤í–‰
uvicorn src.main:app --reload
```

### **ë¡œê¹… ì„¤ì •**

```python
import structlog

structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)
```

## ğŸš€ ë°°í¬

### **Production í™˜ê²½**

```bash
# í”„ë¡œë•ì…˜ ì„œë²„ ì‹¤í–‰
uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 4

# Gunicorn ì‚¬ìš© (ê¶Œì¥)
gunicorn src.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### **Docker Production**

```dockerfile
# Dockerfile.prod
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY src/ ./src/
EXPOSE 8000

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- **[LangSmith ê°€ì´ë“œ](./docs/langsmith-guide.md)**: LLM ì‹¤í—˜ ë° íŠ¸ë ˆì´ì‹±
- **[API ë¬¸ì„œ](http://localhost:8000/docs)**: Swagger UI
- **[ReDoc ë¬¸ì„œ](http://localhost:8000/redoc)**: ëŒ€ì•ˆ API ë¬¸ì„œ

## ğŸ¤ ê¸°ì—¬ ê°€ì´ë“œ

1. **Fork & Clone** ì €ì¥ì†Œ
2. **Feature Branch** ìƒì„±: `git checkout -b feature/new-feature`
3. **ì½”ë“œ ì‘ì„±** ë° **í…ŒìŠ¤íŠ¸ ì¶”ê°€**
4. **ì»¤ë°‹**: `git commit -m "feat: add new feature"`
5. **Push**: `git push origin feature/new-feature`
6. **Pull Request** ìƒì„±

### **ì½”ë”© ìŠ¤íƒ€ì¼**

- **Black**: ì½”ë“œ í¬ë§·íŒ…
- **isort**: import ì •ë ¬
- **flake8**: ë¦°íŒ…
- **mypy**: íƒ€ì… ì²´í¬

```bash
# ì½”ë“œ í¬ë§·íŒ…
black src/
isort src/
flake8 src/
mypy src/
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ“ ì§€ì›

- **ì´ìŠˆ ë¦¬í¬íŠ¸**: GitHub Issues
- **ë¬¸ì„œ**: [API ë¬¸ì„œ](http://localhost:8000/docs)
- **ê°œë°œíŒ€**: dev@saiondo.com

---

**SAIONDO LLM Server** - ì»¤í”Œì„ ìœ„í•œ AI ë¶„ì„ í”Œë«í¼