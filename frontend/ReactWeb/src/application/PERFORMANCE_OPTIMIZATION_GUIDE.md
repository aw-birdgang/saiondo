# âš¡ Service Layer ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

## ğŸ“‹ **ê°œìš”**

ìƒˆë¡œìš´ Service Layer êµ¬ì¡°ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ê³¼ ëª¨ë‹ˆí„°ë§ ì „ëµì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ¯ **ìµœì í™” ëª©í‘œ**

1. **ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•**: ìºì‹± ì „ëµìœ¼ë¡œ API ì‘ë‹µ ì‹œê°„ ê°œì„ 
2. **ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±**: ë©”ëª¨ë¦¬ ë° CPU ì‚¬ìš©ëŸ‰ ìµœì í™”
3. **í™•ì¥ì„±**: íŠ¸ë˜í”½ ì¦ê°€ì— ë”°ë¥¸ ì„±ëŠ¥ ìœ ì§€
4. **ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ ì„±ëŠ¥ ì§€í‘œ ì¶”ì 

## ğŸ“Š **í˜„ì¬ ì„±ëŠ¥ ì§€í‘œ**

### **Base Service ì„±ëŠ¥ ì¸¡ì •**
- ëª¨ë“  ì‘ì—…ì— ëŒ€í•œ ìë™ ì„±ëŠ¥ ì¸¡ì •
- ìƒì„¸í•œ ë¡œê¹…ìœ¼ë¡œ ë³‘ëª© ì§€ì  íŒŒì•…
- ì‘ì—…ë³„ í‰ê·  ì‘ë‹µ ì‹œê°„ ì¶”ì 

### **ìºì‹± ì „ëµ**
- ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹± (MemoryCache)
- TTL ê¸°ë°˜ ìë™ ë§Œë£Œ
- íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”

## ğŸš€ **ìµœì í™” ì „ëµ**

### **1. ìºì‹± ìµœì í™”**

#### **1.1 ìºì‹œ í‚¤ ì „ëµ**

```typescript
// ìµœì í™”ëœ ìºì‹œ í‚¤ ìƒì„±
export class OptimizedCacheService extends BaseCacheService {
  // ì‚¬ìš©ìë³„ ìºì‹œ í‚¤
  generateUserCacheKey(userId: string, dataType: string): string {
    return this.generateCacheKey('user', userId, dataType);
  }

  // ì±„ë„ë³„ ìºì‹œ í‚¤
  generateChannelCacheKey(channelId: string, dataType: string): string {
    return this.generateCacheKey('channel', channelId, dataType);
  }

  // ë¶„ì„ ë°ì´í„° ìºì‹œ í‚¤
  generateAnalyticsCacheKey(timeRange: { start: Date; end: Date }): string {
    const startStr = timeRange.start.toISOString().split('T')[0];
    const endStr = timeRange.end.toISOString().split('T')[0];
    return this.generateCacheKey('analytics', 'report', startStr, endStr);
  }
}
```

#### **1.2 TTL ìµœì í™”**

```typescript
// ë°ì´í„° íƒ€ì…ë³„ ìµœì í™”ëœ TTL
export const OPTIMIZED_TTL_MAP: Record<CacheDataType, number> = {
  // ìì£¼ ë³€ê²½ë˜ì§€ ì•ŠëŠ” ë°ì´í„° (ê¸´ TTL)
  'user_profile': 3600,        // 1ì‹œê°„
  'channel_info': 1800,        // 30ë¶„
  'analytics_report': 7200,    // 2ì‹œê°„
  
  // ìì£¼ ë³€ê²½ë˜ëŠ” ë°ì´í„° (ì§§ì€ TTL)
  'channel_messages': 300,     // 5ë¶„
  'user_activity': 60,         // 1ë¶„
  'real_time_activity': 30,    // 30ì´ˆ
  
  // ê¸°ë³¸ê°’
  'default': 300               // 5ë¶„
};

export class OptimizedTTLService {
  calculateOptimalTTL(dataType: CacheDataType, accessFrequency: number): number {
    const baseTTL = OPTIMIZED_TTL_MAP[dataType] || OPTIMIZED_TTL_MAP.default;
    
    // ì ‘ê·¼ ë¹ˆë„ì— ë”°ë¥¸ TTL ì¡°ì •
    if (accessFrequency > 100) {
      return Math.min(baseTTL * 2, 3600); // ìì£¼ ì ‘ê·¼í•˜ëŠ” ë°ì´í„°ëŠ” TTL ì—°ì¥
    } else if (accessFrequency < 10) {
      return Math.max(baseTTL / 2, 60);   // ì ê²Œ ì ‘ê·¼í•˜ëŠ” ë°ì´í„°ëŠ” TTL ë‹¨ì¶•
    }
    
    return baseTTL;
  }
}
```

#### **1.3 ìºì‹œ ë¬´íš¨í™” ì „ëµ**

```typescript
// ì§€ëŠ¥ì ì¸ ìºì‹œ ë¬´íš¨í™”
export class IntelligentCacheInvalidation extends BaseCacheService {
  // ì‚¬ìš©ì ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
  async invalidateUserRelatedCache(userId: string, operation: string): Promise<void> {
    const patterns = [
      `user:${userId}:*`,
      `user_behavior:${userId}:*`,
      `user_journey:${userId}:*`
    ];

    // í”„ë¡œí•„ ì—…ë°ì´íŠ¸ ì‹œ ì¶”ê°€ ìºì‹œ ë¬´íš¨í™”
    if (operation === 'update_profile') {
      patterns.push(`user_profile:${userId}`);
      patterns.push(`user_stats:${userId}`);
    }

    // ë©”ì‹œì§€ ì „ì†¡ ì‹œ ì±„ë„ ìºì‹œ ë¬´íš¨í™”
    if (operation === 'send_message') {
      patterns.push(`channel:*:messages:*`);
    }

    await Promise.all(
      patterns.map(pattern => this.invalidateCachePattern(pattern))
    );
  }

  // ë°°ì¹˜ ìºì‹œ ë¬´íš¨í™”
  async batchInvalidateCache(operations: Array<{ type: string; id: string }>): Promise<void> {
    const invalidationMap = new Map<string, string[]>();

    // ì‘ì—…ë³„ ë¬´íš¨í™” íŒ¨í„´ ê·¸ë£¹í™”
    operations.forEach(op => {
      if (!invalidationMap.has(op.type)) {
        invalidationMap.set(op.type, []);
      }
      invalidationMap.get(op.type)!.push(op.id);
    });

    // ë°°ì¹˜ë¡œ ìºì‹œ ë¬´íš¨í™” ì‹¤í–‰
    for (const [type, ids] of invalidationMap) {
      const pattern = this.getInvalidationPattern(type, ids);
      await this.invalidateCachePattern(pattern);
    }
  }

  private getInvalidationPattern(type: string, ids: string[]): string {
    switch (type) {
      case 'user':
        return `user:(${ids.join('|')}):*`;
      case 'channel':
        return `channel:(${ids.join('|')}):*`;
      case 'message':
        return `message:(${ids.join('|')})`;
      default:
        return `*:(${ids.join('|')}):*`;
    }
  }
}
```

### **2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìµœì í™”**

#### **2.1 ìƒì„¸í•œ ì„±ëŠ¥ ë©”íŠ¸ë¦­**

```typescript
// í™•ì¥ëœ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
export interface PerformanceMetrics {
  operationId: string;
  operation: string;
  duration: number;
  startTime: Date;
  endTime: Date;
  context: Record<string, any>;
  cacheHit?: boolean;
  cacheKey?: string;
  memoryUsage?: number;
  cpuUsage?: number;
  error?: string;
}

export class AdvancedPerformanceMonitor {
  private metrics: PerformanceMetrics[] = [];
  private readonly maxMetrics = 1000;

  recordMetric(metric: PerformanceMetrics): void {
    this.metrics.push(metric);
    
    // ë©”íŠ¸ë¦­ ê°œìˆ˜ ì œí•œ
    if (this.metrics.length > this.maxMetrics) {
      this.metrics = this.metrics.slice(-this.maxMetrics);
    }
  }

  getAverageResponseTime(operation: string, timeRange?: { start: Date; end: Date }): number {
    const filteredMetrics = this.filterMetrics(operation, timeRange);
    if (filteredMetrics.length === 0) return 0;

    const totalDuration = filteredMetrics.reduce((sum, metric) => sum + metric.duration, 0);
    return totalDuration / filteredMetrics.length;
  }

  getCacheHitRate(operation: string): number {
    const operationMetrics = this.metrics.filter(m => m.operation === operation);
    if (operationMetrics.length === 0) return 0;

    const cacheHits = operationMetrics.filter(m => m.cacheHit).length;
    return cacheHits / operationMetrics.length;
  }

  getErrorRate(operation: string): number {
    const operationMetrics = this.metrics.filter(m => m.operation === operation);
    if (operationMetrics.length === 0) return 0;

    const errors = operationMetrics.filter(m => m.error).length;
    return errors / operationMetrics.length;
  }

  private filterMetrics(operation: string, timeRange?: { start: Date; end: Date }): PerformanceMetrics[] {
    let filtered = this.metrics.filter(m => m.operation === operation);
    
    if (timeRange) {
      filtered = filtered.filter(m => 
        m.startTime >= timeRange.start && m.endTime <= timeRange.end
      );
    }
    
    return filtered;
  }
}
```

#### **2.2 ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ**

```typescript
// ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ë°ì´í„°
export interface PerformanceDashboard {
  currentMetrics: {
    activeOperations: number;
    averageResponseTime: number;
    cacheHitRate: number;
    errorRate: number;
  };
  topSlowOperations: Array<{
    operation: string;
    averageDuration: number;
    callCount: number;
  }>;
  cacheStats: {
    totalKeys: number;
    memoryUsage: number;
    hitRate: number;
    missRate: number;
  };
  recentErrors: Array<{
    operation: string;
    error: string;
    timestamp: Date;
    context: Record<string, any>;
  }>;
}

export class PerformanceDashboardService {
  constructor(private performanceMonitor: AdvancedPerformanceMonitor) {}

  getDashboardData(): PerformanceDashboard {
    const now = new Date();
    const lastHour = new Date(now.getTime() - 60 * 60 * 1000);

    return {
      currentMetrics: {
        activeOperations: this.getActiveOperations(),
        averageResponseTime: this.getOverallAverageResponseTime(lastHour),
        cacheHitRate: this.getOverallCacheHitRate(lastHour),
        errorRate: this.getOverallErrorRate(lastHour)
      },
      topSlowOperations: this.getTopSlowOperations(lastHour),
      cacheStats: this.getCacheStatistics(),
      recentErrors: this.getRecentErrors(lastHour)
    };
  }

  private getActiveOperations(): number {
    const now = new Date();
    const activeThreshold = new Date(now.getTime() - 5 * 60 * 1000); // 5ë¶„ ì´ë‚´
    
    return this.performanceMonitor.metrics.filter(
      m => m.endTime >= activeThreshold
    ).length;
  }

  private getOverallAverageResponseTime(timeRange: Date): number {
    const metrics = this.performanceMonitor.metrics.filter(
      m => m.startTime >= timeRange
    );
    
    if (metrics.length === 0) return 0;
    
    const totalDuration = metrics.reduce((sum, m) => sum + m.duration, 0);
    return totalDuration / metrics.length;
  }

  private getOverallCacheHitRate(timeRange: Date): number {
    const metrics = this.performanceMonitor.metrics.filter(
      m => m.startTime >= timeRange && m.cacheHit !== undefined
    );
    
    if (metrics.length === 0) return 0;
    
    const cacheHits = metrics.filter(m => m.cacheHit).length;
    return cacheHits / metrics.length;
  }

  private getOverallErrorRate(timeRange: Date): number {
    const metrics = this.performanceMonitor.metrics.filter(
      m => m.startTime >= timeRange
    );
    
    if (metrics.length === 0) return 0;
    
    const errors = metrics.filter(m => m.error).length;
    return errors / metrics.length;
  }

  private getTopSlowOperations(timeRange: Date): Array<{ operation: string; averageDuration: number; callCount: number }> {
    const operationStats = new Map<string, { totalDuration: number; count: number }>();
    
    this.performanceMonitor.metrics
      .filter(m => m.startTime >= timeRange)
      .forEach(m => {
        if (!operationStats.has(m.operation)) {
          operationStats.set(m.operation, { totalDuration: 0, count: 0 });
        }
        
        const stats = operationStats.get(m.operation)!;
        stats.totalDuration += m.duration;
        stats.count += 1;
      });

    return Array.from(operationStats.entries())
      .map(([operation, stats]) => ({
        operation,
        averageDuration: stats.totalDuration / stats.count,
        callCount: stats.count
      }))
      .sort((a, b) => b.averageDuration - a.averageDuration)
      .slice(0, 10);
  }

  private getCacheStatistics(): any {
    // ì‹¤ì œ ìºì‹œ í†µê³„ ë°˜í™˜
    return {
      totalKeys: 0,
      memoryUsage: 0,
      hitRate: 0,
      missRate: 0
    };
  }

  private getRecentErrors(timeRange: Date): Array<{ operation: string; error: string; timestamp: Date; context: Record<string, any> }> {
    return this.performanceMonitor.metrics
      .filter(m => m.startTime >= timeRange && m.error)
      .map(m => ({
        operation: m.operation,
        error: m.error!,
        timestamp: m.startTime,
        context: m.context
      }))
      .sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime())
      .slice(0, 20);
  }
}
```

### **3. ë©”ëª¨ë¦¬ ìµœì í™”**

#### **3.1 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§**

```typescript
// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
export class MemoryMonitor {
  private memorySnapshots: Array<{ timestamp: Date; usage: number }> = [];
  private readonly maxSnapshots = 100;

  recordMemoryUsage(): void {
    const usage = process.memoryUsage();
    const totalUsage = usage.heapUsed + usage.external + usage.arrayBuffers;
    
    this.memorySnapshots.push({
      timestamp: new Date(),
      usage: totalUsage
    });

    if (this.memorySnapshots.length > this.maxSnapshots) {
      this.memorySnapshots = this.memorySnapshots.slice(-this.maxSnapshots);
    }
  }

  getMemoryTrend(): { current: number; average: number; trend: 'increasing' | 'decreasing' | 'stable' } {
    if (this.memorySnapshots.length < 2) {
      return { current: 0, average: 0, trend: 'stable' };
    }

    const current = this.memorySnapshots[this.memorySnapshots.length - 1].usage;
    const average = this.memorySnapshots.reduce((sum, snap) => sum + snap.usage, 0) / this.memorySnapshots.length;
    
    const recentSnapshots = this.memorySnapshots.slice(-10);
    const recentAverage = recentSnapshots.reduce((sum, snap) => sum + snap.usage, 0) / recentSnapshots.length;
    
    let trend: 'increasing' | 'decreasing' | 'stable' = 'stable';
    if (recentAverage > average * 1.1) {
      trend = 'increasing';
    } else if (recentAverage < average * 0.9) {
      trend = 'decreasing';
    }

    return { current, average, trend };
  }

  getMemoryAlerts(): string[] {
    const alerts: string[] = [];
    const { current, average, trend } = this.getMemoryTrend();

    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í‰ê· ë³´ë‹¤ 50% ì´ìƒ ë†’ì„ ë•Œ
    if (current > average * 1.5) {
      alerts.push(`High memory usage: ${this.formatBytes(current)} (${Math.round(current / average * 100)}% of average)`);
    }

    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•  ë•Œ
    if (trend === 'increasing') {
      alerts.push('Memory usage is trending upward');
    }

    // ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì˜ì‹¬ (ì§€ì†ì ì¸ ì¦ê°€)
    if (trend === 'increasing' && this.memorySnapshots.length >= 20) {
      const firstHalf = this.memorySnapshots.slice(0, 10);
      const secondHalf = this.memorySnapshots.slice(-10);
      
      const firstHalfAvg = firstHalf.reduce((sum, snap) => sum + snap.usage, 0) / firstHalf.length;
      const secondHalfAvg = secondHalf.reduce((sum, snap) => sum + snap.usage, 0) / secondHalf.length;
      
      if (secondHalfAvg > firstHalfAvg * 1.3) {
        alerts.push('Potential memory leak detected');
      }
    }

    return alerts;
  }

  private formatBytes(bytes: number): string {
    const sizes = ['Bytes', 'KB', 'MB', 'GB'];
    if (bytes === 0) return '0 Bytes';
    const i = Math.floor(Math.log(bytes) / Math.log(1024));
    return Math.round(bytes / Math.pow(1024, i) * 100) / 100 + ' ' + sizes[i];
  }
}
```

#### **3.2 ìºì‹œ ë©”ëª¨ë¦¬ ìµœì í™”**

```typescript
// ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ìºì‹œ
export class MemoryOptimizedCache implements ICache {
  private cache = new Map<string, { data: any; expiry: number; size: number }>();
  private totalSize = 0;
  private readonly maxSize = 100 * 1024 * 1024; // 100MB
  private readonly maxEntries = 10000;

  async set(key: string, data: any, ttl: number = 300): Promise<void> {
    const size = this.estimateSize(data);
    
    // ìºì‹œ í¬ê¸° ì œí•œ í™•ì¸
    if (size > this.maxSize) {
      throw new Error(`Data size ${size} exceeds maximum cache size ${this.maxSize}`);
    }

    // ê³µê°„ í™•ë³´
    await this.ensureSpace(size);

    const expiry = Date.now() + ttl * 1000;
    this.cache.set(key, { data, expiry, size });
    this.totalSize += size;

    // ì—”íŠ¸ë¦¬ ìˆ˜ ì œí•œ í™•ì¸
    if (this.cache.size > this.maxEntries) {
      this.evictOldest();
    }
  }

  async get(key: string): Promise<any | null> {
    const entry = this.cache.get(key);
    
    if (!entry) {
      return null;
    }

    // ë§Œë£Œ í™•ì¸
    if (Date.now() > entry.expiry) {
      this.cache.delete(key);
      this.totalSize -= entry.size;
      return null;
    }

    return entry.data;
  }

  async delete(key: string): Promise<void> {
    const entry = this.cache.get(key);
    if (entry) {
      this.totalSize -= entry.size;
      this.cache.delete(key);
    }
  }

  async clear(): Promise<void> {
    this.cache.clear();
    this.totalSize = 0;
  }

  async has(key: string): Promise<boolean> {
    const entry = this.cache.get(key);
    if (!entry) return false;
    
    if (Date.now() > entry.expiry) {
      this.cache.delete(key);
      this.totalSize -= entry.size;
      return false;
    }
    
    return true;
  }

  async keys(): Promise<string[]> {
    const now = Date.now();
    const validKeys: string[] = [];
    
    for (const [key, entry] of this.cache.entries()) {
      if (now <= entry.expiry) {
        validKeys.push(key);
      } else {
        this.cache.delete(key);
        this.totalSize -= entry.size;
      }
    }
    
    return validKeys;
  }

  private async ensureSpace(requiredSize: number): Promise<void> {
    if (this.totalSize + requiredSize <= this.maxSize) {
      return;
    }

    // LRU ë°©ì‹ìœ¼ë¡œ ì˜¤ë˜ëœ ì—”íŠ¸ë¦¬ ì œê±°
    const entries = Array.from(this.cache.entries())
      .sort((a, b) => a[1].expiry - b[1].expiry);

    for (const [key, entry] of entries) {
      this.cache.delete(key);
      this.totalSize -= entry.size;
      
      if (this.totalSize + requiredSize <= this.maxSize) {
        break;
      }
    }
  }

  private evictOldest(): void {
    const oldestKey = this.cache.keys().next().value;
    if (oldestKey) {
      const entry = this.cache.get(oldestKey)!;
      this.cache.delete(oldestKey);
      this.totalSize -= entry.size;
    }
  }

  private estimateSize(data: any): number {
    const jsonString = JSON.stringify(data);
    return Buffer.byteLength(jsonString, 'utf8');
  }

  getStats(): { totalSize: number; entryCount: number; hitRate: number } {
    return {
      totalSize: this.totalSize,
      entryCount: this.cache.size,
      hitRate: 0 // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” íˆíŠ¸ìœ¨ ê³„ì‚°
    };
  }
}
```

### **4. ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”**

#### **4.1 ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”**

```typescript
// ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
export class ParallelProcessingOptimizer {
  // ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ì‘ì—… ì‹¤í–‰
  async executeParallel<T>(
    tasks: Array<() => Promise<T>>,
    maxConcurrency: number = 5
  ): Promise<T[]> {
    const results: T[] = [];
    const executing = new Set<Promise<void>>();

    for (const task of tasks) {
      if (executing.size >= maxConcurrency) {
        await Promise.race(executing);
      }

      const promise = task().then(result => {
        results.push(result);
        executing.delete(promise);
      });

      executing.add(promise);
    }

    await Promise.all(executing);
    return results;
  }

  // ë°°ì¹˜ ì²˜ë¦¬
  async processBatch<T, R>(
    items: T[],
    processor: (item: T) => Promise<R>,
    batchSize: number = 10
  ): Promise<R[]> {
    const results: R[] = [];
    
    for (let i = 0; i < items.length; i += batchSize) {
      const batch = items.slice(i, i + batchSize);
      const batchResults = await Promise.all(
        batch.map(item => processor(item))
      );
      results.push(...batchResults);
    }
    
    return results;
  }

  // ìºì‹œ ë¯¸ë¦¬ ë¡œë”©
  async preloadCache(
    keys: string[],
    loader: (key: string) => Promise<any>,
    ttl: number = 300
  ): Promise<void> {
    const cache = new MemoryOptimizedCache();
    
    await this.executeParallel(
      keys.map(key => async () => {
        try {
          const data = await loader(key);
          await cache.set(key, data, ttl);
        } catch (error) {
          console.error(`Failed to preload cache for key: ${key}`, error);
        }
      }),
      5
    );
  }
}
```

## ğŸ“ˆ **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ**

### **ì‹¤ì‹œê°„ ì§€í‘œ**

```typescript
// ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ì»´í¬ë„ŒíŠ¸
export interface PerformanceMetrics {
  responseTime: {
    p50: number;
    p95: number;
    p99: number;
  };
  throughput: {
    requestsPerSecond: number;
    activeConnections: number;
  };
  cache: {
    hitRate: number;
    missRate: number;
    memoryUsage: number;
  };
  errors: {
    rate: number;
    recentErrors: Array<{ operation: string; error: string; timestamp: Date }>;
  };
  memory: {
    usage: number;
    trend: 'increasing' | 'decreasing' | 'stable';
    alerts: string[];
  };
}

export class PerformanceDashboard {
  constructor(
    private performanceMonitor: AdvancedPerformanceMonitor,
    private memoryMonitor: MemoryMonitor
  ) {}

  async getMetrics(): Promise<PerformanceMetrics> {
    const now = new Date();
    const lastMinute = new Date(now.getTime() - 60 * 1000);

    return {
      responseTime: this.calculateResponseTimePercentiles(lastMinute),
      throughput: this.calculateThroughput(lastMinute),
      cache: await this.getCacheMetrics(),
      errors: this.calculateErrorMetrics(lastMinute),
      memory: this.getMemoryMetrics()
    };
  }

  private calculateResponseTimePercentiles(timeRange: Date): { p50: number; p95: number; p99: number } {
    const metrics = this.performanceMonitor.metrics.filter(
      m => m.startTime >= timeRange
    );

    if (metrics.length === 0) {
      return { p50: 0, p95: 0, p99: 0 };
    }

    const durations = metrics.map(m => m.duration).sort((a, b) => a - b);
    
    return {
      p50: this.getPercentile(durations, 50),
      p95: this.getPercentile(durations, 95),
      p99: this.getPercentile(durations, 99)
    };
  }

  private getPercentile(sortedArray: number[], percentile: number): number {
    const index = Math.ceil((percentile / 100) * sortedArray.length) - 1;
    return sortedArray[index] || 0;
  }

  private calculateThroughput(timeRange: Date): { requestsPerSecond: number; activeConnections: number } {
    const metrics = this.performanceMonitor.metrics.filter(
      m => m.startTime >= timeRange
    );

    const durationInSeconds = (Date.now() - timeRange.getTime()) / 1000;
    const requestsPerSecond = metrics.length / durationInSeconds;

    return {
      requestsPerSecond: Math.round(requestsPerSecond * 100) / 100,
      activeConnections: this.getActiveConnections()
    };
  }

  private async getCacheMetrics(): Promise<{ hitRate: number; missRate: number; memoryUsage: number }> {
    // ì‹¤ì œ ìºì‹œ í†µê³„ ë°˜í™˜
    return {
      hitRate: 0.85,
      missRate: 0.15,
      memoryUsage: 0
    };
  }

  private calculateErrorMetrics(timeRange: Date): { rate: number; recentErrors: Array<{ operation: string; error: string; timestamp: Date }> } {
    const metrics = this.performanceMonitor.metrics.filter(
      m => m.startTime >= timeRange
    );

    const totalRequests = metrics.length;
    const errors = metrics.filter(m => m.error);
    const errorRate = totalRequests > 0 ? errors.length / totalRequests : 0;

    const recentErrors = errors
      .map(m => ({ operation: m.operation, error: m.error!, timestamp: m.startTime }))
      .sort((a, b) => b.timestamp.getTime() - a.timestamp.getTime())
      .slice(0, 10);

    return {
      rate: Math.round(errorRate * 10000) / 100, // ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
      recentErrors
    };
  }

  private getMemoryMetrics(): { usage: number; trend: 'increasing' | 'decreasing' | 'stable'; alerts: string[] } {
    const trend = this.memoryMonitor.getMemoryTrend();
    const alerts = this.memoryMonitor.getMemoryAlerts();

    return {
      usage: trend.current,
      trend: trend.trend,
      alerts
    };
  }

  private getActiveConnections(): number {
    // ì‹¤ì œ í™œì„± ì—°ê²° ìˆ˜ ë°˜í™˜
    return 0;
  }
}
```

## ğŸ¯ **ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸**

### **ìºì‹± ìµœì í™”**
- [ ] ìºì‹œ í‚¤ ì „ëµ ìµœì í™”
- [ ] TTL ê°’ ì¡°ì •
- [ ] ìºì‹œ ë¬´íš¨í™” ì „ëµ ê°œì„ 
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

### **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**
- [ ] ìƒì„¸í•œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- [ ] ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ êµ¬í˜„
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„

### **ë©”ëª¨ë¦¬ ìµœì í™”**
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- [ ] ìºì‹œ í¬ê¸° ì œí•œ ì„¤ì •
- [ ] ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°ì§€
- [ ] ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”

### **ë¹„ë™ê¸° ì²˜ë¦¬**
- [ ] ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„
- [ ] ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
- [ ] ìºì‹œ ë¯¸ë¦¬ ë¡œë”©
- [ ] ë™ì‹œì„± ì œí•œ ì„¤ì •

## ğŸš€ **ë‹¤ìŒ ë‹¨ê³„**

1. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ êµ¬í˜„**: ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
2. **ìºì‹± ì „ëµ ìµœì í™”**: ë°ì´í„° íƒ€ì…ë³„ TTL ì¡°ì •
3. **ë©”ëª¨ë¦¬ ìµœì í™”**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ì œí•œ
4. **ì•Œë¦¼ ì‹œìŠ¤í…œ**: ì„±ëŠ¥ ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼
5. **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**: ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë° ë³‘ëª© ì§€ì  íŒŒì•…
6. **ë¬¸ì„œí™”**: ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ ì—…ë°ì´íŠ¸ 